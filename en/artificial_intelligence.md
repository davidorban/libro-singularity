## Artificial intelligence 
### The Nature of Intelligence
The meat of this book could be a philosophical analysis of what is intelligence, and whether it is possible to describe it in scientific terms, or, rather, if it represents an essence that it irreducible, and irreproducible.

Indeed, this has been the occupation, in various forms, of philosophers for thousands of years. Including the nature of truth, beauty, right and wrong, morality, ethics and esthetics, philosophy had the run of the field, unencumbered by practical considerations. To the contrary, the division of knowledge into two fields of abstract understanding and of that with practical consequences, with this second being frowned upon and seen as inferior by the followers of the first, has been a mainstay of Western philosophy since Aristoteles. 

There are several assumptions in this book, and the fact that intelligence can be understood, analyzed, and reproduced is one of its fundamental ones. In more recent books by philosophers who don’t disdain being understood by many, there are wonderful arguments to why this should be the case.

In general, for the purpose of this book we will define intelligence as the capacity of matter to organize in a way that allows it to seek solutions to goals through plotting a path of action towards them, and organizing both abstract and concrete resources to achieve them.

The human brain is a lump of matter that is endowed with a certain degree of intelligence. And on purpose I use the expression instead of “mind”. We will avoid the pitfall of dualism, that has bogged down philosophy trying to understand a mind that just inhabits the brain, dragging Descart into arguments about homunculi and fruitlessly searching for the connecting tissue through which the mind is attached to the brain. Under this assumption the brain expresses the mind, and the mind is what the brain does.

### The Mechanical Turk 
During the ‘700s a fascinating contraption toured the courts of Europe’s kingdoms. Designed by the Hungarian Wolfgang von Kempelen, it was a large box on top of which a wooden doll sit, today we would call it a robot. It played chess, and beat anybody attempting a game with it, unerringly, with mechanical precision. Von Kempelen’s claim, that he built an automaton capable of acting with intelligence, was unraveled when it became apparent that the box housed a midget. Indeed good at chess, the midget pretended to be the intelligence behind the robot. It actually was the homunculus of an artificial setup for mechanical intelligence. It constituted an artificial artificial intelligence.

### Turing tests for humans
When the first electrical computers were born, in the ’40s of the 20th century, Alan Turing, formulated a novel test for the intelligence of machines. The Turing test as it is called today, asserts that there is no reason to believe that a machine is intelligent, if it is deemed to be intelligent through its actions by a team of human judges. During the test the setup hides the machine from the humans, and mix it and its output with other humans that during the test can pretend to be machines wanting the judges to believe them or the humans they are. Turing called it “the imitation game”, probably believing it to be less fundamental than the the fascination with which it is seen now. Too frequently and somewhat bombastically one or an other of the media sources announces that the Turing test has been passed. Universally, when the transcripts of the dialog typed out between the winning machine and its human judges becomes available, it appears that the machine, or rather its programmers, hid behind pretend jokes, changing of the subject, and other trivia.

### Chess playing experts
In 1994 XXX the then World Champion of chess, Gerry Kasparov, was beaten by a machine, called Deep Blue, especially designed and built by IBM for this purpose. The machine could definitely not attempt to pass the Turing test, in its imitation game based on written dialog encompassing general subjects. However, with its hardware and software specialized in analyzing and discarding millions of moves in the tree of possibilities of the game of chess, until it found what it decided was the best one to make in a given configuration, it nonetheless faked to be intelligent in the game perfectly enough to beat and even infuriate Kasparov. 

If the Turing test, the imitation game, consist in convincing a group of humans that a machine can have a human-like dialog, following the rules of syntax and semantics, then the Kasparov test, the chess game, consists in convincing a chess player that he lost to a machine that plays following the rules of chess. And relevantly enough, in this case there is actually no difference between the machine that pretends to know chess and one that does know chess.

During the various stages of the tournament between Kasparov and Deep Blue the engineers from IBM tweaked the algorithms of the machine, and the Russian champion strongly protested. The machine should not be able to learn during its play? The tweaks that constituted an increase in its smarts, and possibly contributed to its winning were admitted by the judges of the tournament.

## Expert systems and restricted artificial intelligence
Running on specialized hardware like IBM’s Deep Blue, or more general computer architectures, even personal computers, systems that exhibit the decision making power of a human in a given specialized field are called expert systems. The field of artificial intelligence (AI) was dominated by the approach of expert systems in the ’80s of the 20th century. In fields as diverse as medical diagnostics or financial planning, the knowledge of experts in a given area was encoded in rules that were put in motion by inference engines capable of applying them according to the data provided, in order to generate a recommendation for a course of action: what possible illness the symptoms suggested, or which loan was most appropriate for a given financial situation.

These expert systems were relatively successful, and are still employed in various fields, but did not represent an attempt to create a general model of intelligence, and could not be the stepping stone on the path towards the general artificial intelligence that would be able to be an expert in any field whatsoever.

### Hopes and disillusions
Many of the original practitioners of AI have held the belief that they could quickly build computers that exhibited higher capacities for thinking, creativity and problem solving. They were taking advantage of the stimulating environments of academia, from MIT to Stanford and elsewhere, to establish laboratories in the ‘60s studying what was possible. And many of them left academia to raise funding from industry or venture capital in the hopes of creating scalable and sustainable innovation through the application of what they learned in the labs. 

Most of the claims that were made, even taking into account the constant development of the hardware that was available to be at the basis of the software systems for AI, went unfulfilled. Or at least they did not achieve the scales that the funders needed to justify their continued investments. By the ’80s what was called “AI winter” descended, and it looked like the field would not change the world as deeply as originally thought.

This is a common effect of misunderstanding exponentials. Overexcitement by the outsiders of their feeble understanding of the underlying principles, coupled with the eagerness of experts to deliver solid results looks at a few data points with a linear interpolation. But the linear growth at the beginning of an exponential is actually higher! So those who underestimate the power of the exponential further on, are also bound to make the mistake of overestimating it at the beginning.

### Applications of AI
Many, maybe even most, of the original goals of the ‘60s have been achieved and in cases overachieved by systems built recently. It took longer than originally anticipated with a linear mindset, but now the systems that we could justifiably call AI are everywhere, and are positively impacting our daily lives, at the degree and more so than the original founders of the discipline foresaw.

XXX
### Optimization
### Control systems
### Speech recognition and speech synthesis
### Vision systems, object and face recognition
### Common sense reasoning
### Natural language processing
### Learning and problem solving
### …

### The role of learning
When computers were born, their architecture initially was not that of what we today recognize as a computer. It more resembled a specialized tool, that could be used only for a given purpose, rather than that of the universally adaptable instrument we use daily today. The hardware was designed to be optimized and literally wired for that single task, and it was not feasible to rearrange it to do anything else. 

Only after a while with the stored memory computer, implemented with the Von Neumann architecture, that did not distinguish between numbers representing data and numbers representing instructions, that it was possible to talk about a universal computer. Even then an additional development was necessary to complete the concept of programming the computer, and of representing the programs in higher level formalisms, abstract languages that could then be translated, compiled, into machine language, the steps directly executed by the computer.

Writing these programs was a new art at the middle of the 20th century, and even if certain basic components, like branching and loops have been conceptualized already before they became practical elements of a running program, more sophisticated tools needed to be developed to be able to juggle larger and larger programs, making sure that they would be able to execute without problems. 

How the programs could be written, and if the programs themselves could be looked at as data, with other parts of the program rewriting them as needed eventually, changing the behavior of the main program being executed, was something that Turing already considered, and likened to the role of learning in humans.

If we can build a program that plays chess, an other one that makes medical diagnoses, or financial recommendations, can we build programs that are good at all of those things and others? Can we build a program that, running on a sophisticated and powerful computer, can be put in front of a problem, any problem, and find a way to analyze it, to garner the resources needed, and to solve it? Can the program look at its results and decide if they were optimal, or if, with additional data available, there would be now a better way of achieving success? To learn, solve problems, in a completely universal manner, where its programming is not fixed, but fluidly adapts to the needs represented by the environment? That is what we call Artificial General Intelligence.

